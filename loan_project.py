# -*- coding: utf-8 -*-
"""Loan_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15aoa6WGX6z1FUxJvZfvDSJxCyqmIFXX5

#**Step 1 :Import Libraries**
"""

import pandas as pd

"""#**Step 2: Load the Data**"""

# Load the train and test datasets

train_data = pd.read_csv('/content/train_ctrUa4K.csv')
test_data = pd.read_csv('/content/test_lAUu6dG (1).csv')

"""#**Step 3: Exploratory Data Analysis**"""

train_data.head()

test_data.head()

train_data.info()

test_data.info()

test_data.shape

train_data.shape

test_data.dtypes

train_data.dtypes

#View duplicates
test_data.duplicated().sum()

#View duplicates
train_data.duplicated().sum()

#Check null values / Empty Cells in each column
test_data.isna().sum()

#Check null values / Empty Cells in each column
train_data.isna().sum()

"""#**Step 4: Data Preprocessing**

#### Handle Missing Values
"""

# Define columns by type for easy handling
categorical_cols = ['Gender', 'Married', 'Dependents', 'Self_Employed', 'Credit_History']
numerical_cols = ['LoanAmount', 'Loan_Amount_Term']

# Fill missing values in train dataset
for col in categorical_cols:
    train_data[col].fillna(train_data[col].mode()[0], inplace=True)

for col in numerical_cols:
    train_data[col].fillna(train_data[col].median(), inplace=True)

# Fill missing values in test dataset
for col in categorical_cols:
    test_data[col].fillna(test_data[col].mode()[0], inplace=True)

for col in numerical_cols:
    test_data[col].fillna(test_data[col].median(), inplace=True)

"""####Encode Categorical Variables"""

# Perform one-hot encoding for categorical variables, dropping the first level to avoid multicollinearity
train_data = pd.get_dummies(train_data, columns=['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'], drop_first=True)
test_data = pd.get_dummies(test_data, columns=['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area'], drop_first=True)

"""####Feature Engineering (Optional)"""

# Create a new feature for total income in both train and test datasets
train_data['TotalIncome'] = train_data['ApplicantIncome'] + train_data['CoapplicantIncome']
test_data['TotalIncome'] = test_data['ApplicantIncome'] + test_data['CoapplicantIncome']

# Drop original income columns if not needed
train_data.drop(['ApplicantIncome', 'CoapplicantIncome'], axis=1, inplace=True)
test_data.drop(['ApplicantIncome', 'CoapplicantIncome'], axis=1, inplace=True)

"""####Scaling Numerical Features (Optional)"""

from sklearn.preprocessing import StandardScaler

# List of numerical columns to scale
numerical_features = ['LoanAmount', 'Loan_Amount_Term', 'TotalIncome']

# Initialize the scaler
scaler = StandardScaler()

# Fit and transform the train data
train_data[numerical_features] = scaler.fit_transform(train_data[numerical_features])

# Only transform the test data
test_data[numerical_features] = scaler.transform(test_data[numerical_features])

# Verify no missing values remain
print(train_data.isnull().sum().sum())  # Should print 0
print(test_data.isnull().sum().sum())   # Should print 0

# Check for column consistency between train and test datasets
print(train_data.columns)
print(test_data.columns)

"""#**Step 5: Modeling**

####a) Split the Data
"""

from sklearn.model_selection import train_test_split

# Separate features and target variable
X = train_data.drop(columns=['Loan_ID', 'Loan_Status'])
y = train_data['Loan_Status'].apply(lambda x: 1 if x == 'Y' else 0)  # Convert target to 1 (Yes) and 0 (No)

# Split into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""#### a) Train Multiple Models"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

#Letâ€™s train several models and evaluate their accuracy.
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score

# Initialize models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42)
}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    accuracy = accuracy_score(y_val, y_pred)
    print(f"{name} Accuracy: {accuracy:.4f}")

from sklearn.ensemble import VotingClassifier

# Ensemble using VotingClassifier
voting_clf = VotingClassifier(
    estimators=[('lr', LogisticRegression(max_iter=1000)),
                ('rf', RandomForestClassifier(random_state=42)),
                ('gb', GradientBoostingClassifier(random_state=42))],
    voting='hard'
)

voting_clf.fit(X_train, y_train)
voting_accuracy = voting_clf.score(X_val, y_val)
print("Voting Classifier Accuracy:", voting_accuracy)

from sklearn.model_selection import GridSearchCV

# Example for Random Forest hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best accuracy:", grid_search.best_score_)

"""####Select the Best Model"""

best_model = RandomForestClassifier(random_state=42)
best_model.fit(X, y)

"""####Predict on the Test Data"""

# Prepare test data by dropping Loan_ID (but keep it for the final submission file)
X_test = test_data.drop(columns=['Loan_ID'])
test_pred = best_model.predict(X_test)
test_pred = ['Y' if pred == 1 else 'N' for pred in test_pred]

# Create the submission DataFrame
submission = pd.DataFrame({
    'Loan_ID': test_data['Loan_ID'],
    'Loan_Status': test_pred
})
print(submission.head())

# Save the submission file
submission.to_csv('/content/sample_submission_49d68Cx (1).csv', index=False)
print("Submission file created successfully!")

